# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17yVa18dV3lzgmEGXZqHh0mOZGR7IxbJI
"""

!pip install fitz
!pip install pymupdf
!pip install transformers
!pip install torch
!pip install numpy
!pip install scikit-learn

import fitz  # PyMuPDF for extracting text from PDFs
from transformers import AutoModel, AutoTokenizer
import torch
import numpy as np

# Extract text from all pages of a PDF file
def extract_text_from_pdf(pdf_path):
    document = fitz.open(pdf_path)
    all_text = []
    for page_num in range(len(document)):
        page = document.load_page(page_num)
        text = page.get_text()
        all_text.append(text)
    return all_text

# Embed text using a pre-trained model
def embed_text(text, model, tokenizer):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
    with torch.no_grad():
        embeddings = model(**inputs).last_hidden_state.mean(dim=1)
    return embeddings

# Search for relevant page and answer based on query
def search(query, embeddings, documents, model, tokenizer, top_k=1):
    query_embedding = embed_text(query, model, tokenizer)
    similarities = [torch.cosine_similarity(query_embedding, doc_emb, dim=1).item() for doc_emb in embeddings]
    sorted_indices = np.argsort(similarities)[::-1][:top_k]
    most_relevant_index = sorted_indices[0]
    most_relevant_page = most_relevant_index + 1  # Adjust for 1-based index
    answer_text = documents[most_relevant_index]
    return most_relevant_page, answer_text

# Load the pre-trained model and tokenizer
model_name = 'sentence-transformers/all-MiniLM-L6-v2'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# Define the path to your PDF
pdf_path = '/content/DL BOOK .pdf'  # Replace with your actual PDF path

# Extract text from all pages of the PDF
pdf_texts = extract_text_from_pdf(pdf_path)

# Generate embeddings for each page's text
embeddings = [embed_text(text, model, tokenizer) for text in pdf_texts]

# Perform a search with a query
query = "Single Computational Layer: The Perceptron"  # Replace with your desired query
most_relevant_page, answer_text = search(query, embeddings, pdf_texts, model, tokenizer)
print(f"Most Relevant Page: {most_relevant_page}")
print(f"Answer Text: {answer_text}")

import fitz  # PyMuPDF for extracting text from PDFs
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Function to perform textual search in a PDF
def search_in_pdf(pdf_path, query):
    # Extract text from all pages of the PDF
    def extract_text_from_pdf(pdf_path):
        document = fitz.open(pdf_path)
        all_text = []
        for page_num in range(len(document)):
            page = document.load_page(page_num)
            text = page.get_text()
            all_text.append(text)
        return all_text

    # Extract text from the PDF
    pdf_texts = extract_text_from_pdf(pdf_path)

    # Create a TF-IDF vectorizer
    vectorizer = TfidfVectorizer()

    # Fit the vectorizer on the PDF text and transform it to obtain TF-IDF vectors
    tfidf_vectors = vectorizer.fit_transform(pdf_texts)

    # Transform the query into a TF-IDF vector
    query_vector = vectorizer.transform([query])

    # Compute cosine similarity between the query vector and all document vectors
    similarities = cosine_similarity(query_vector, tfidf_vectors).flatten()

    # Find the index of the most similar page
    most_similar_index = similarities.argmax()

    # Return the most relevant page number and its text
    most_relevant_page = most_similar_index + 1  # Adjust for 1-based index
    answer_text = pdf_texts[most_similar_index]

    return most_relevant_page, answer_text

# Example usage:
pdf_path = '/content/DL BOOK .pdf'  # Replace with your actual PDF path
query = "Single Computational Layer: The Perceptron"

most_relevant_page, answer_text = search_in_pdf(pdf_path, query)
print(f"Most Relevant Page: {most_relevant_page}")
print(f"Answer Text: {answer_text}")

import fitz  # PyMuPDF for extracting text from PDFs
from transformers import AutoModel, AutoTokenizer
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Function to perform hybrid search in a PDF
def hybrid_search_in_pdf(pdf_path, query, model_name='sentence-transformers/all-MiniLM-L6-v2', top_k=1):
    # Extract text from all pages of the PDF
    def extract_text_from_pdf(pdf_path):
        document = fitz.open(pdf_path)
        all_text = []
        for page_num in range(len(document)):
            page = document.load_page(page_num)
            text = page.get_text()
            all_text.append(text)
        return all_text

    # Embed text using a pre-trained model
    def embed_text(text, model, tokenizer):
        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
        with torch.no_grad():
            embeddings = model(**inputs).last_hidden_state.mean(dim=1)
        return embeddings

    # Create TF-IDF vectors from text
    def create_tfidf_vectors(texts):
        vectorizer = TfidfVectorizer()
        tfidf_vectors = vectorizer.fit_transform(texts)
        return vectorizer, tfidf_vectors

    # Load pre-trained model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)

    # Extract text from all pages of the PDF
    pdf_texts = extract_text_from_pdf(pdf_path)

    # Embeddings for each page's text
    page_embeddings = [embed_text(text, model, tokenizer) for text in pdf_texts]

    # TF-IDF vectors for textual search
    tfidf_vectorizer, tfidf_vectors = create_tfidf_vectors(pdf_texts)

    # Embed the query using the pre-trained model
    query_embedding = embed_text(query, model, tokenizer)

    # Compute cosine similarity between query embedding and page embeddings
    similarities = [torch.cosine_similarity(query_embedding, emb, dim=1).item() for emb in page_embeddings]
    semantic_scores = np.array(similarities)

    # Use TF-IDF to compute textual similarity
    query_vector = tfidf_vectorizer.transform([query])
    tfidf_similarities = cosine_similarity(query_vector, tfidf_vectors).flatten()

    # Combine semantic and textual scores
    combined_scores = semantic_scores + tfidf_similarities

    # Rank pages based on combined scores
    ranked_indices = np.argsort(combined_scores)[::-1][:top_k]
    ranked_pages = [(idx + 1, pdf_texts[idx]) for idx in ranked_indices]  # Adjust for 1-based index

    return ranked_pages

# Example usage:
pdf_path = '/content/DL BOOK .pdf'  # Replace with your actual PDF path
query = "Single Computational Layer: The Perceptron"
top_k = 1  # Number of top results to retrieve

results = hybrid_search_in_pdf(pdf_path, query, top_k=top_k)

# Print the top result
if results:
    page_number, page_text = results[0]
    print(f"Most Relevant Page: {page_number}")
    print(f"Answer Text: {page_text}")
else:
    print("No relevant page found.")

from google.colab import drive
drive.mount('/content/drive')

HF_TOKEN = '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'

with open('/content/drive/MyDrive/hf_token.txt', 'w') as f:
    f.write(HF_TOKEN)

import os

with open('/content/drive/MyDrive/hf_token.txt', 'r') as f:
    HF_TOKEN = f.read().strip()

os.environ['HF_TOKEN'] = HF_TOKEN

from huggingface_hub import login

login(token=HF_TOKEN)

!pip install huggingface_hub

import fitz  # PyMuPDF for extracting text from PDFs
from transformers import AutoModel, AutoTokenizer
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Function to perform hybrid search in a PDF
def hybrid_search_in_pdf(pdf_path, query, model_name='sentence-transformers/all-MiniLM-L6-v2', top_k=1):
    # Extract text from all pages of the PDF
    def extract_text_from_pdf(pdf_path):
        document = fitz.open(pdf_path)
        all_text = []
        for page_num in range(len(document)):
            page = document.load_page(page_num)
            text = page.get_text()
            all_text.append(text)
        return all_text

    # Embed text using a pre-trained model
    def embed_text(text, model, tokenizer):
        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
        with torch.no_grad():
            embeddings = model(**inputs).last_hidden_state.mean(dim=1)
        return embeddings

    # Create TF-IDF vectors from text
    def create_tfidf_vectors(texts):
        vectorizer = TfidfVectorizer()
        tfidf_vectors = vectorizer.fit_transform(texts)
        return vectorizer, tfidf_vectors

    # Load pre-trained model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)

    # Extract text from all pages of the PDF
    pdf_texts = extract_text_from_pdf(pdf_path)

    # Embeddings for each page's text
    page_embeddings = [embed_text(text, model, tokenizer) for text in pdf_texts]

    # TF-IDF vectors for textual search
    tfidf_vectorizer, tfidf_vectors = create_tfidf_vectors(pdf_texts)

    # Embed the query using the pre-trained model
    query_embedding = embed_text(query, model, tokenizer)

    # Compute cosine similarity between query embedding and page embeddings
    similarities = [torch.cosine_similarity(query_embedding, emb, dim=1).item() for emb in page_embeddings]
    semantic_scores = np.array(similarities)

    # Use TF-IDF to compute textual similarity
    query_vector = tfidf_vectorizer.transform([query])
    tfidf_similarities = cosine_similarity(query_vector, tfidf_vectors).flatten()

    # Combine semantic and textual scores
    combined_scores = semantic_scores + tfidf_similarities

    # Rank pages based on combined scores
    ranked_indices = np.argsort(combined_scores)[::-1][:top_k]
    ranked_pages = [(idx + 1, pdf_texts[idx]) for idx in ranked_indices]  # Adjust for 1-based index

    return ranked_pages

# Example usage:
pdf_path = '/content/DL BOOK .pdf'  # Replace with your actual PDF path
query = "Single Computational Layer: The Perceptron"
top_k = 1  # Number of top results to retrieve

results = hybrid_search_in_pdf(pdf_path, query, top_k=top_k)

# Print the top result
if results:
    page_number, page_text = results[0]
    print(f"Most Relevant Page: {page_number}")
    print(f"Answer Text: {page_text}")
else:
    print("No relevant page found.")

